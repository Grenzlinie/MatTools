{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv('OPENAI_API_KEY'),\n",
    "  base_url=\"https://test-cloudflare-7nq.pages.dev/v1/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymatgen-analysis-defects单元测试文件读取和分割\n",
    "\n",
    "(Read pymatgen-analysis-defects unit test files and split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "class PythonCodeParser:\n",
    "    def __init__(self):\n",
    "        self.parser = self.setup_parser()\n",
    "\n",
    "    def setup_parser(self):\n",
    "        PY_LANGUAGE = Language('build_python_parser/my-languages.so', 'python')\n",
    "        parser = Parser()\n",
    "        parser.set_language(PY_LANGUAGE)\n",
    "        return parser\n",
    "\n",
    "    def parse_code(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            source_code = f.read()\n",
    "\n",
    "        tree = self.parser.parse(bytes(source_code, \"utf8\"))\n",
    "        root_node = tree.root_node\n",
    "\n",
    "        imports, classes, functions, variables = [], [], [], []\n",
    "\n",
    "        for node in root_node.children:\n",
    "            if node.type in ('import_statement', 'import_from_statement'):\n",
    "                imports.append(source_code[node.start_byte:node.end_byte].strip())\n",
    "            elif node.type == 'decorated_definition':\n",
    "                function_node = node.children[-1]  # The actual function definition\n",
    "                function_start = node.start_byte\n",
    "                function_end = function_node.end_byte\n",
    "                functions.append(source_code[function_start:function_end].strip())\n",
    "            elif node.type == 'class_definition':\n",
    "                classes.append(source_code[node.start_byte:node.end_byte].strip())\n",
    "            elif node.type == 'function_definition':\n",
    "                functions.append(source_code[node.start_byte:node.end_byte].strip())\n",
    "            elif node.type == 'expression_statement' and '=' in source_code[node.start_byte:node.end_byte]:\n",
    "                variables.append(source_code[node.start_byte:node.end_byte].strip())\n",
    "\n",
    "        data = {\n",
    "            \"uuid\": str(uuid.uuid4()),\n",
    "            \"filename\": file_path,\n",
    "            \"imports\": imports,\n",
    "            \"classes\": classes,  # Store classes as a list\n",
    "            \"global functions\": functions,  # Store functions as a list\n",
    "            \"global variables\": variables  # Store variables as a list\n",
    "        }\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def save_to_json(self, file_path, output_json_path):\n",
    "        data = self.parse_code(file_path)\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            \n",
    "            \n",
    "def process_directory(root_dir, parser):\n",
    "    # Create the 'txt_code' directory if it doesn't exist\n",
    "    output_root_dir = os.path.join(os.getcwd(), 'code_segments/pymatgen_analysis_defects/')\n",
    "    if not os.path.exists(output_root_dir):\n",
    "        os.makedirs(output_root_dir)\n",
    "\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py') and file != '__init__.py':\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                \n",
    "                # Create corresponding subdirectory structure in 'txt_code'\n",
    "                relative_subdir = os.path.relpath(subdir, root_dir)\n",
    "                output_subdir = os.path.join(output_root_dir, relative_subdir)\n",
    "                \n",
    "                if not os.path.exists(output_subdir):\n",
    "                    os.makedirs(output_subdir)\n",
    "                \n",
    "                json_output_path = os.path.join(output_subdir, file.replace('.py', '.json'))\n",
    "                \n",
    "                # Save JSON file\n",
    "                parser.save_to_json(file_path, json_output_path)\n",
    "\n",
    "# Example usage\n",
    "parser = PythonCodeParser()\n",
    "process_directory('../tool_source_code/pymatgen-analysis-defects/tests', parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "class JSONAssembler:\n",
    "    def __init__(self, base_file_path):\n",
    "        self.base_file_path = base_file_path\n",
    "\n",
    "    def read_json(self, file_path: str) -> dict:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    def assemble_base(self):\n",
    "        data = self.read_json(self.base_file_path)\n",
    "        output = \"\"\n",
    "\n",
    "        for key in [\"imports\", \"global variables\", \"classes\", \"global functions\"]:\n",
    "            if key in data and data[key]:\n",
    "                if isinstance(data[key], list):\n",
    "                    output += \"\\n\".join(data[key]) + \"\\n\"\n",
    "                else:\n",
    "                    output += data[key] + \"\\n\"\n",
    "\n",
    "        return output.strip()\n",
    "\n",
    "    def assemble_others(self, json_files):\n",
    "        outputs = []\n",
    "\n",
    "        for file_path in json_files:\n",
    "            if file_path == self.base_file_path:\n",
    "                continue  # Skip the base file\n",
    "\n",
    "            data:dict = self.read_json(file_path)\n",
    "            imports = \"\\n\".join(data.get(\"imports\", []))\n",
    "            global_vars = \"\\n\".join(data.get(\"global variables\", []))\n",
    "\n",
    "            for class_def in data.get(\"classes\", []):\n",
    "                assembled = \"\\n\".join(filter(None, [imports, global_vars, class_def]))\n",
    "                outputs.append(assembled)\n",
    "\n",
    "            for function_def in data.get(\"global functions\", []):\n",
    "                assembled = \"\\n\".join(filter(None, [imports, global_vars, function_def]))\n",
    "                outputs.append(assembled)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def gather_json_files(self, dir_path):\n",
    "        json_files = []\n",
    "        for root, _, files in os.walk(dir_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    json_files.append(os.path.join(root, file))\n",
    "        return json_files\n",
    "\n",
    "    def process_and_output(self, other_json_dir):\n",
    "        # Process base file\n",
    "        base_output = self.assemble_base()\n",
    "        # Gather other JSON files, excluding the base file\n",
    "        other_json_files = self.gather_json_files(other_json_dir)\n",
    "        # Assemble other files\n",
    "        other_outputs = self.assemble_others(other_json_files)\n",
    "        return base_output, other_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "base_file = '../code_segments/pymatgen_analysis_defects/conftest.json'\n",
    "other_json_dir = '../code_segments/pymatgen_analysis_defects'\n",
    "assembler = JSONAssembler(base_file)\n",
    "base_output, other_output = assembler.process_and_output(other_json_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA问题集生成Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extract_params_from_test.txt\", \"r\") as file:\n",
    "    EXTRACT_PARAMS_PROMPT= file.read()\n",
    "with open(\"generate_new_unit_test.txt\", \"r\") as file:\n",
    "    GENERATE_UNIT_TEST_PROMPT = file.read()\n",
    "with open(\"build_question_from_test.txt\", \"r\") as file:\n",
    "    BUILD_QUESTION_PROMPT = file.read()\n",
    "with open(\"build_question_from_test_user.txt\", \"r\") as file:\n",
    "    BUILD_QUESTION_PROMPT_USER = file.read()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_params_prompt(other_code):\n",
    "    UNIT_TEST_PROMPT = \"**Unit Test Code:**\\n```python\\n{unit_test_code}\\n```\".format(unit_test_code=other_code)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": EXTRACT_PARAMS_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": UNIT_TEST_PROMPT\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    )\n",
    "    match = re.search(r'```json(.*?)```', response.choices[0].message.content, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(\"No match found in the response.\")\n",
    "        print(other_code)\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "def build_question_from_test(base_code, other_code, properties_json):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": BUILD_QUESTION_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": BUILD_QUESTION_PROMPT_USER.format(unit_test_code=other_code, properties_json=properties_json, file_reading_functions=base_code)\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    )\n",
    "    match = re.search(r'<question>(.*?)</question>', response.choices[0].message.content, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(\"No match found in the response.\")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "def generate_new_unit_test(properties_json):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": GENERATE_UNIT_TEST_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"**Properties JSON:**\\n```json\\n{properties_json}\\n```\".format(properties_json=properties_json)\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    )\n",
    "    match = re.search(r'```python(.*?)```', response.choices[0].message.content, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(\"No match found in the response.\")\n",
    "        print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "logger.add(\"defect_questions.log\", rotation=None)\n",
    "defect_questions = []\n",
    "for i in range(len(other_output)):\n",
    "    properties_json_str = extract_params_prompt(other_output[i])\n",
    "    if properties_json_str:\n",
    "        question = build_question_from_test(base_output, other_output[i], properties_json_str)\n",
    "        new_unit_test = generate_new_unit_test(properties_json_str)\n",
    "    if question and new_unit_test:\n",
    "            defect_questions.append({\n",
    "                \"properties_json_str\": properties_json_str,\n",
    "                \"question\": question,\n",
    "                \"new_unit_test\": new_unit_test\n",
    "            })\n",
    "    logger.info(defect_questions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('defect_questions.json', 'w') as json_file:\n",
    "    json.dump(defect_questions, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据\n",
    "\n",
    "show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('defect_questions.json', 'r') as json_file:\n",
    "    defect_questions = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from collections import defaultdict\n",
      "from pathlib import Path\n",
      "import pytest\n",
      "from monty.serialization import loadfn\n",
      "from pymatgen.analysis.defects.core import PeriodicSite, Substitution\n",
      "from pymatgen.analysis.defects.thermo import DefectEntry, FormationEnergyDiagram\n",
      "from pymatgen.analysis.phase_diagram import PhaseDiagram\n",
      "from pymatgen.core import Element, Structure\n",
      "from pymatgen.core.periodic_table import Specie\n",
      "from pymatgen.io.vasp.outputs import WSWQ, Chgcar, Locpot, Procar, Vasprun\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def test_dir():\n",
      "    return Path.cwd() / 'tool_source_code/pymatgen-analysis-defects/tests/test_files/'\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def gan_struct(test_dir):\n",
      "    return Structure.from_file(test_dir / \"GaN.vasp\")\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def stable_entries_Mg_Ga_N(test_dir):\n",
      "    return loadfn(test_dir / \"stable_entries_Mg_Ga_N.json\")\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def defect_Mg_Ga(gan_struct):\n",
      "    ga_site = gan_struct[0]\n",
      "    mg_site = PeriodicSite(Specie(\"Mg\"), ga_site.frac_coords, gan_struct.lattice)\n",
      "    return Substitution(gan_struct, mg_site)\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def data_Mg_Ga(test_dir):\n",
      "    \"\"\"Get the data in the following format:\n",
      "    {\n",
      "        \"bulk_sc\": {\n",
      "            \"vasp_run\": Vasprun,\n",
      "            \"locpot\": Locpot,\n",
      "        },\n",
      "        \"q=1\": {\n",
      "            \"vasp_run\": Vasprun,\n",
      "            \"locpot\": Locpot,\n",
      "        },\n",
      "        ...\n",
      "    }.\n",
      "    \"\"\"\n",
      "    root_dir = test_dir / \"Mg_Ga\"\n",
      "    data = defaultdict(dict)\n",
      "    for fold in root_dir.glob(\"./*\"):\n",
      "        if not fold.is_dir():\n",
      "            continue\n",
      "        data[fold.name] = {\n",
      "            \"vasprun\": Vasprun(fold / \"vasprun.xml.gz\"),\n",
      "            \"locpot\": Locpot.from_file(fold / \"LOCPOT.gz\"),\n",
      "        }\n",
      "    return data\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def defect_entries_and_plot_data_Mg_Ga(data_Mg_Ga, defect_Mg_Ga):\n",
      "    bulk_locpot = data_Mg_Ga[\"bulk_sc\"][\"locpot\"]\n",
      "\n",
      "    def get_data(q):\n",
      "        computed_entry = data_Mg_Ga[f\"q={q}\"][\"vasprun\"].get_computed_entry(\n",
      "            inc_structure=True\n",
      "        )\n",
      "        defect_locpot = data_Mg_Ga[f\"q={q}\"][\"locpot\"]\n",
      "\n",
      "        def_entry = DefectEntry(\n",
      "            defect=defect_Mg_Ga, charge_state=q, sc_entry=computed_entry\n",
      "        )\n",
      "        frey_summary = def_entry.get_freysoldt_correction(\n",
      "            defect_locpot=defect_locpot, bulk_locpot=bulk_locpot, dielectric=14\n",
      "        )\n",
      "        return def_entry, frey_summary\n",
      "\n",
      "    defect_entries = dict()\n",
      "    plot_data = dict()\n",
      "    for qq in [-2, -1, 0, 1]:\n",
      "        defect_entry, frey_summary = get_data(qq)\n",
      "        defect_entries[qq] = defect_entry\n",
      "        plot_data[qq] = frey_summary.metadata[\"plot_data\"]\n",
      "    return defect_entries, plot_data\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def chgcar_fe3o4(test_dir):\n",
      "    return Chgcar.from_file(test_dir / \"CHGCAR.Fe3O4.vasp\")\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def v_ga(test_dir):\n",
      "    res = dict()\n",
      "    for q1, q2 in [(0, -1), (-1, 0)]:\n",
      "        ccd_dir = test_dir / f\"v_Ga/ccd_{q1}_{q2}\"\n",
      "        vaspruns = [Vasprun(ccd_dir / f\"{i}/vasprun.xml\") for i in [0, 1, 2]]\n",
      "        wswq_dir = ccd_dir / \"wswqs\"\n",
      "        wswq_files = [f for f in wswq_dir.glob(\"WSWQ*\")]\n",
      "        wswq_files.sort(\n",
      "            key=lambda x: int(x.name.split(\".\")[1])\n",
      "        )  # does stem work for non-zipped files?\n",
      "        wswqs = [WSWQ.from_file(f) for f in wswq_files]\n",
      "        # wswqs = [WSWQ.from_file(ccd_dir / \"wswqs\" / f\"WSWQ.{i}.gz\") for i in [0, 1, 2]]\n",
      "        res[(q1, q2)] = {\n",
      "            \"vaspruns\": vaspruns,\n",
      "            \"procar\": Procar(ccd_dir / \"1/PROCAR\"),\n",
      "            \"wswqs\": wswqs,\n",
      "        }\n",
      "    return res\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def v_N_GaN(test_dir):\n",
      "    \"\"\"More complex.\"\"\"\n",
      "    bulk_locpot = Locpot.from_file(test_dir / \"v_N_GaN/bulk/LOCPOT.gz\")\n",
      "    return {\n",
      "        \"bulk_locpot\": bulk_locpot,\n",
      "        \"defect_locpots\": {\n",
      "            -1: Locpot.from_file(test_dir / \"v_N_GaN/q=-1/LOCPOT.gz\"),\n",
      "            0: Locpot.from_file(test_dir / \"v_N_GaN/q=0/LOCPOT.gz\"),\n",
      "            1: Locpot.from_file(test_dir / \"v_N_GaN/q=1/LOCPOT.gz\"),\n",
      "            2: Locpot.from_file(test_dir / \"v_N_GaN/q=2/LOCPOT.gz\"),\n",
      "        },\n",
      "    }\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def basic_fed(data_Mg_Ga, defect_entries_and_plot_data_Mg_Ga, stable_entries_Mg_Ga_N):\n",
      "    bulk_vasprun = data_Mg_Ga[\"bulk_sc\"][\"vasprun\"]\n",
      "    bulk_bs = bulk_vasprun.get_band_structure()\n",
      "    vbm = bulk_bs.get_vbm()[\"energy\"]\n",
      "    bulk_entry = bulk_vasprun.get_computed_entry(inc_structure=False)\n",
      "    defect_entries, _ = defect_entries_and_plot_data_Mg_Ga\n",
      "\n",
      "    def_ent_list = list(defect_entries.values())\n",
      "    # test the constructor with materials project phase diagram\n",
      "    atomic_entries = list(\n",
      "        filter(lambda x: len(x.composition.elements) == 1, stable_entries_Mg_Ga_N)\n",
      "    )\n",
      "    pd = PhaseDiagram(stable_entries_Mg_Ga_N)\n",
      "    # test the constructor with atomic entries\n",
      "    # this is the one we will use for the rest of the tests\n",
      "    fed = FormationEnergyDiagram.with_atomic_entries(\n",
      "        defect_entries=def_ent_list,\n",
      "        atomic_entries=atomic_entries,\n",
      "        vbm=vbm,\n",
      "        inc_inf_values=False,\n",
      "        phase_diagram=pd,\n",
      "        bulk_entry=bulk_entry,\n",
      "    )\n",
      "    assert len(fed.chempot_limits) == 3\n",
      "\n",
      "    # dataframe conversion\n",
      "    df = fed.as_dataframe()\n",
      "    assert df.shape == (4, 5)\n",
      "\n",
      "    # test that you can get the Ga-rich chempot\n",
      "    cp = fed.get_chempots(rich_element=Element(\"Ga\"))\n",
      "    assert cp[Element(\"Ga\")] == pytest.approx(0, abs=1e-2)\n",
      "    fed.band_gap = 2\n",
      "    return fed\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def hd0(v_ga):\n",
      "    vaspruns = v_ga[(0, -1)][\"vaspruns\"]\n",
      "    procar = v_ga[(0, -1)][\"procar\"]\n",
      "    hd0 = HarmonicDefect.from_vaspruns(\n",
      "        vaspruns,\n",
      "        charge_state=0,\n",
      "        procar=procar,\n",
      "        store_bandstructure=True,\n",
      "    )\n",
      "    assert hd0.spin_index == 1\n",
      "    assert pytest.approx(hd0.distortions[1]) == 0.0\n",
      "    assert pytest.approx(hd0.omega_eV) == 0.03268045792725\n",
      "    assert hd0.defect_band == [(138, 0, 1), (138, 1, 1)]\n",
      "    assert hd0._get_ediff(output_order=\"bks\").shape == (216, 2, 2)\n",
      "    assert hd0._get_ediff(output_order=\"skb\").shape == (2, 2, 216)\n",
      "    return hd0\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def hd1(v_ga):\n",
      "    vaspruns = v_ga[(-1, 0)][\"vaspruns\"]\n",
      "    procar = v_ga[(-1, 0)][\"procar\"]\n",
      "    hd1 = HarmonicDefect.from_vaspruns(\n",
      "        vaspruns,\n",
      "        charge_state=1,\n",
      "        procar=procar,\n",
      "        store_bandstructure=True,\n",
      "    )\n",
      "    assert pytest.approx(hd1.omega_eV) == 0.03341323356861477\n",
      "    return hd1\n",
      "@pytest.fixture(scope=\"module\")\n",
      "def formation_energy_diagram(\n",
      "    data_Mg_Ga, defect_entries_and_plot_data_Mg_Ga, stable_entries_Mg_Ga_N\n",
      "):\n",
      "    bulk_vasprun = data_Mg_Ga[\"bulk_sc\"][\"vasprun\"]\n",
      "    bulk_bs = bulk_vasprun.get_band_structure()\n",
      "    vbm = bulk_bs.get_vbm()[\"energy\"]\n",
      "    bulk_entry = bulk_vasprun.get_computed_entry(inc_structure=False)\n",
      "    defect_entries, _ = defect_entries_and_plot_data_Mg_Ga\n",
      "\n",
      "    def_ent_list = list(defect_entries.values())\n",
      "    # test the constructor with materials project phase diagram\n",
      "    atomic_entries = list(\n",
      "        filter(lambda x: len(x.composition.elements) == 1, stable_entries_Mg_Ga_N)\n",
      "    )\n",
      "    pd = PhaseDiagram(stable_entries_Mg_Ga_N)\n",
      "\n",
      "    # test basic constructor\n",
      "    fed_ = FormationEnergyDiagram(\n",
      "        bulk_entry=bulk_entry,\n",
      "        defect_entries=def_ent_list,\n",
      "        vbm=vbm,\n",
      "        pd_entries=stable_entries_Mg_Ga_N,\n",
      "        inc_inf_values=True,  # include the two additional points at infinity\n",
      "    )\n",
      "    assert len(fed_.chempot_limits) == 5\n",
      "\n",
      "    # test the constructor with atomic entries\n",
      "    # this is the one we will use for the rest of the tests\n",
      "    fed = FormationEnergyDiagram.with_atomic_entries(\n",
      "        defect_entries=def_ent_list,\n",
      "        atomic_entries=atomic_entries,\n",
      "        vbm=vbm,\n",
      "        inc_inf_values=False,\n",
      "        phase_diagram=pd,\n",
      "        bulk_entry=bulk_entry,\n",
      "    )\n",
      "    assert len(fed.chempot_limits) == 3\n",
      "\n",
      "    # dataframe conversion\n",
      "    df = fed.as_dataframe()\n",
      "    assert df.shape == (4, 5)\n",
      "\n",
      "    # test that you can get the Ga-rich chempot\n",
      "    cp = fed.get_chempots(rich_element=Element(\"Ga\"))\n",
      "    assert cp[Element(\"Ga\")] == pytest.approx(0, abs=1e-2)\n",
      "\n",
      "    return fed\n",
      "@pytest.fixture()\n",
      "def plot_fn():\n",
      "    def _plot(*args):\n",
      "        plot_formation_energy_diagrams(*args, save=True, show=True)\n",
      "        yield plt.show()\n",
      "        plt.close(\"all\")\n",
      "        os.remove(\"formation_energy_diagram.png\")\n",
      "\n",
      "    return _plot\n"
     ]
    }
   ],
   "source": [
    "print(base_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pymatgen.analysis.defects.plotting.thermo import (\n",
      "    plot_chempot_2d,\n",
      "    plot_formation_energy_diagrams,\n",
      ")\n",
      "from pymatgen.core import Element\n",
      "def test_chempot_plot(basic_fed) -> None:\n",
      "    plot_chempot_2d(basic_fed, x_element=Element(\"Mg\"), y_element=Element(\"Ga\"))\n"
     ]
    }
   ],
   "source": [
    "print(other_output[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(defect_questions[number]['properties_json_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(defect_questions[number]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(defect_questions[number]['new_unit_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割数据到文件夹里\n",
    "\n",
    "split triplets to folder (question_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = 'question_segments/pymatgen_analysis_defects'\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(directory_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "for defect_question in defect_questions:\n",
    "    try:\n",
    "        properties_json = json.loads(defect_question['properties_json_str'])\n",
    "    except:\n",
    "        print(defect_question)\n",
    "    folder_path = os.path.join(directory_path, properties_json['JSON_File_Name'])\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    with open(os.path.join(folder_path, 'properties.json'), 'w') as json_file:\n",
    "        json.dump(properties_json, json_file, indent=4)\n",
    "    with open(os.path.join(folder_path, 'question.txt'), 'w') as txt_file:\n",
    "        txt_file.write(defect_question['question'])\n",
    "    with open(os.path.join(folder_path, 'new_unit_test.py'), 'w') as py_file:\n",
    "        py_file.write(defect_question['new_unit_test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mattoolben",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
